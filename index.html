<!doctype html>
<html>
  <head lang="en">
    <meta charset="UTF-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />

    <title>
      Agentic 3D Scene Generation with Spatially Contextualized VLMs
    </title>

    <link rel="icon" type="image/png" href="img/studio-set.png" />

    <meta name="description" content="Agentic 3D Scene Generation with Spatially Contextualized VLMs" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="1216" />
    <meta property="og:image:height" content="832" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Agentic 3D Scene Generation with Spatially Contextualized VLMs" />
    <meta property="og:description" content="Explore how VLMs use spatial context for agentic 3D scene generation." />
    <meta name="twitter:description" content="Explore how VLMs use spatial context for agentic 3D scene generation." />



    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"
    />
    <link
    rel="stylesheet"
    href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="css/app.css" />
    <link rel="stylesheet" href="css/fontawesome.all.min.css" />

    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-8ZERS5BVPS");
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script
      type="text/javascript"
      async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"
    ></script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>
    <script src="js/app.js"></script>
    <style>
      .highlight-text {
        background-color: #fff3cd;
        padding: 2px 5px;
        border-radius: 3px;
        color: #000;
        transition: all 0.3s ease;
      }
      ul, li {
        text-align: left;
      }
      .large-text {
        font-size: 24px;
      }
      .masonry-item {
        width: 25%;
        aspect-ratio: 640 / 480;
        overflow: hidden;
      }

      .masonry-item,
      .masonry-sizer{
        width: 25%;
      }
      @media (max-width: 991.98px){
        .masonry-item,
        .masonry-sizer{
          width: 33.333%;
        }
      }
      @media (max-width: 575.98px){
        .masonry-item,
        .masonry-sizer{
          width: 50%;
        }
      }

      .video-wrapper {
        position: relative;
      }
      .video-wrapper figcaption {
        position: absolute;
        bottom: 0;
        left: 0;
        right: 0;
        padding: 4px 6px;
        background: rgba(0, 0, 0, 0.6);
        color: #fff;
        font-size: 0.9rem;
        line-height: 1.2;
        opacity: 0;
        transition: opacity 0.2s ease;
      }
      .video-wrapper:hover figcaption {
        opacity: 1;
      }

      
      .masonry-item video,
      .masonry-item img {
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      #c1 {
        position: fixed;
        top: -10%;
        left: 0;
        width: 100%;
        height: 100%;
        z-index: -1;
        pointer-events: none;
      }
      .container-lg {
        position: relative;
        background: rgba(255,255,255,0.8);
        border-radius: 10px;
        padding: 20px;
      }
      .CodeMirror {
        background: rgba(255,255,255,0);
      }
    </style>
    
    <!-- Add slick carousel CSS -->
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>
    
    <!-- Add jQuery (required by slick) -->
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    
    <!-- Add slick carousel JS -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
    <canvas id="c1"></canvas>

    <style>
      .video-option {
        background-color: #ffffff;
        border: 2px solid #c5e4cc;
        color: #4d7b5a;
        padding: 10px;
        border-radius: 6px;
        margin-bottom: 10px;
        cursor: pointer;
        font-style: italic;
        transition: all 0.2s ease;
      }
    
      .video-option:hover {
        background-color: #f3fbf5;
      }
    
      .video-option.active {
        background-color: #c5e4cc;
        color: white;
        border: 2px solid transparent;
      }
    </style>

<style>
  .video-option2 {
    background-color: #ffffff;
    border: 2px solid #c5e4cc;
    color: #4d7b5a;
    padding: 3px;
    border-radius: 6px;
    margin-bottom: 10px;
    cursor: pointer;
    font-style: italic;
    transition: all 0.2s ease;
  }

  .video-option2:hover {
    background-color: #f3fbf5;
  }

  .video-option2.active {
    background-color: #c5e4cc;
    color: white;
    border: 2px solid transparent;
  }
</style>

<style>
  .video-option3 {
    background-color: #ffffff;
    border: 2px solid #c5e4cc;
    color: #4d7b5a;
    padding: 3px;
    border-radius: 6px;
    margin-bottom: 10px;
    cursor: pointer;
    font-style: italic;
    transition: all 0.2s ease;
  }

  .video-option3:hover {
    background-color: #f3fbf5;
  }

  .video-option3.active {
    background-color: #c5e4cc;
    color: white;
    border: 2px solid transparent;
  }
</style>
    
  </head>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const options = document.querySelectorAll('.video-option');
      const video = document.getElementById('mainVideo');
  
      options.forEach(opt => {
        opt.addEventListener('click', () => {
          options.forEach(o => o.classList.remove('active'));
          opt.classList.add('active');
          const src = opt.getAttribute('data-src');
          video.src = src;
          video.load();
          video.play();
        });
      });
  
      // Auto-activate the first option on page load
      if (options.length > 0) {
        options[0].classList.add('active');
        video.src = options[0].getAttribute('data-src');
        video.load();
        video.play();
      }
    });
  </script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const options = document.querySelectorAll('.video-option2');
      const video = document.getElementById('mainVideo2');
  
      options.forEach(opt => {
        opt.addEventListener('click', () => {
          options.forEach(o => o.classList.remove('active'));
          opt.classList.add('active');
          const src = opt.getAttribute('data-src');
          video.src = src;
          video.load();
          video.play();
        });
      });
  
      // Auto-activate the first option on page load
      if (options.length > 0) {
        options[0].classList.add('active');
        video.src = options[0].getAttribute('data-src');
        video.load();
        video.play();
      }
    });
  </script>
  <body
    style="
      padding: 5%;
      padding-top: min(15px, 5%);
      padding-bottom: min(5px, 5%);
      width: 100%;
    "
  >
    <div
      class="container-lg text-center"
      style="max-width: 1500px; margin: auto"
      id="main"
    >
      <header role="banner">
        <div class="row">
          <h1 class="col-md-8 offset-md-2 text-center">
            <span style="font-size: 36px; font-weight: bold; display: block;">
              Agentic 3D Scene Generation
            </span>
            <span style="font-size: 36px; font-weight: bold; display: block;">
              with Spatially Contextualized VLMs
            </span>
          </h1>          
        </div>
        <div class="row text-center">
          <div class="container-fluid text-center px-0">
            <ul
              class="list-inline d-flex flex-wrap justify-content-center gap-0 mb-0"
              style="max-width: 800px; margin: auto">
              <li class="list-inline-item">
                <a style="font-size: 18px; font-weight: 500;" href="https://xinhangliu.com/">Xinhang Liu</a>
                <sup>1</sup>
              </li>
              <li class="list-inline-item">
                <a style="font-size: 18px; font-weight: 500;" href="https://yuwingtai.github.io/">Yu-Wing Tai</a>
                <sup>2</sup>
              </li>
              <li class="list-inline-item">
                <a style="font-size: 18px; font-weight: 500;" href="https://cse.hkust.edu.hk/~cktang/bio.html">Chi-Keung Tang</a>
                <sup>1</sup>
              </li>
            </ul>
          </div>
          <div
            class="col-md-12 text-center"
            style="font-size: 16px; margin-top: 10px; line-height: 1.6"
          >
            <sup>1</sup>HKUST &nbsp;&nbsp;&nbsp;&nbsp;
            <sup>2</sup>Dartmouth College
          </div>
        </div>
        <br />
        <div class="row text-center">
          <div class="d-flex justify-content-center flex-wrap gap-3">
            <div class="text-center">
              <a
                href="https://arxiv.org/abs/2505.20129"
                class="external-link is-normal"
              >
                <img src="img/arxiv.png" alt="ArXiv" height="30" width="30" />
              </a>
              <div
                class="normal"
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                  width: 100px;
                  font-size: 16px;
                "
              >
                <b>Paper</b>
              </div>
            </div>
            <div class="text-center">
              <a href="#" class="external-link is-normal">
                <img src="img/github.png" alt="Github" height="30" width="30" />
              </a>
              <div
                class="normal"
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                  width: 100px;
                  font-size: 16px; 
                "
              >
                <b>Code</b>
              </div>
            </div>
            <div class="text-center">
              <a href="#" class="external-link is-normal">
                <img
                  src="img/huggingface.png"
                  alt="HuggingFace"
                  height="30"
                  width="30"
                />
              </a>
              <div
                class="normal"
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                  width: 100px;
                  font-size: 16px;
                "
              >
                <b>Model Card</b>
              </div>
            </div>
          </div>
        </div>
        <br /><br />
      </header>

      <main role="main">
        <div
          id="toc-sidebar"
          class="toc-block"
          style="
            position: fixed;
            left: 10px;
            top: 20%;
            transform: translateY(-50%);
            z-index: 1000;
            background: white;
            padding: 15px;
          "
        >
          <h5 style="margin-bottom: 10px">Sections</h5>
          <ul
            id="toc-list"
            style="list-style: none; padding: 0; margin: 0; text-align: left"
          ></ul>
        </div>

        <!-- Bootstrap Modal -->
        <div
          class="modal fade"
          id="imageModal"
          tabindex="-1"
          aria-hidden="true"
        >
          <div class="modal-dialog modal-dialog-centered">
            <div class="modal-content">
              <div class="modal-body text-center">
                <img id="modalImage" class="img-fluid" />
              </div>
            </div>
          </div>
        </div>

        <!-- Abstract Section -->
        <div class="row">
          <div class="col-md-8 offset-md-2">
            
            <h2 id="intro" style="text-align: left">Abstract</h2>
            <p class="text-justify" style="text-align: left">
              Despite recent advances in multimodal content generation with vision-language models (VLMs), 
              their ability to reason about and generate structured 3D scenes remains underexplored—limiting 
              their potential in tasks like embodied AI, immersive simulations, and interactive 3D environments. 
              We introduce a new paradigm that augments VLMs with a continually evolving spatial context, composed of a scene portrait, 
              a semantically labeled point cloud, and a scene hypergraph capturing unary, binary, and higher-order spatial relationships. 
              This structured, geometry-aware memory allows VLMs to integrate multimodal reasoning with 3D spatial understanding. 
              Building on this foundation, we develop an agentic 3D scene generation pipeline that iteratively reads from and updates 
              the spatial context. The pipeline includes high-quality asset generation with geometric restoration, 
              environment setup with automatic verification, and ergonomic adjustment guided by the hypergraph. 
              Experiments show strong generalization across diverse and challenging inputs, and demonstrate that 
              spatial context enables downstream tasks such as interactive scene editing and path 
              planning.
            </p>
            <img
              src="assets/pipeline.jpg"
              alt="Pipeline Overview"
              class="w-100 d-block mx-auto"
              style="min-width: min(500px, 100%)"
            />


          </div>
        </div>


<!-- Spatial Context Section -->
<div class="row">
  <div class="col-md-8 offset-md-2">

    <h2 id="spatial-context" style="text-align: left">Spatially Contextualized VLMs</h2>

    <p class="text-justify" style="text-align: left">
      Our framework equips vision-language models (VLMs) with a structured spatial context that integrates multimodal cues to establish a grounded understanding of a scene’s semantics, layout, and object relationships. This context is initialized using the user’s multimodal input, which may include one or more images, textual descriptions, or both. It consists of the following components:
    </p>

    <ul style="text-align: left; line-height: 1.8">
      <li><b>Scene portrait:</b> A high-level representation of the scene, including a detailed textual description of the layout, objects, style, and atmosphere, along with an image that serves as a visual proxy.</li>

      <li><b>Semantically labeled point cloud:</b> A colored point cloud generated from the scene portrait image(s) using a geometric foundation model. Each 3D point is assigned an RGB value and an instance label based on object masks.</li>

      <li><b>Scene hypergraph:</b> A structure representing spatial relationships. Nodes correspond to object instances, while hyperedges encode unary (e.g., clearance), binary (e.g., contact, alignment), and higher-order (e.g., equidistance, symmetry) spatial relations.</li>
    </ul>

    <p class="text-justify" style="text-align: left">
      The spatial context is dynamic—it undergoes iterative <b>readout</b> and <b>update</b> as the scene evolves. The VLM actively consults the spatial context to guide tasks such as asset generation and layout refinement. When changes are needed, it triggers a replacement or adjustment of relevant components to ensure the spatial context remains coherent and up-to-date for all subsequent reasoning and generation steps.
    </p>
    

  </div>
</div>

<!-- Agentic 3D Scene Generation Section -->
<div class="row">
  <div class="col-md-8 offset-md-2">

    <h2 id="agentic-generation" style="text-align: left">Agentic 3D Scene Generation</h2>

    <p class="text-justify" style="text-align: left">
      With vision-language models (VLMs) injected with spatial context, we introduce an agentic framework for 3D scene generation, where the VLM actively consults the context to guide scene synthesis and dynamically refines it to reflect ongoing changes in the environment.
    </p>

    <ul style="text-align: left; line-height: 1.8">
      <li>
        <b>Asset Generation:</b> For each object in the scene hypergraph, the VLM extracts its point cloud segment and, if incomplete, restores it using a lightweight geometric module. The segment is rendered from a canonical view and passed to a mesh generator to produce a textured 3D asset.
      </li>

      <li>
        <b>Layout Planning:</b> Each generated mesh is aligned to its corresponding point cloud segment using centroid-based initialization and ICP-based refinement.
      </li>

      <li>
        <b>Environment Setup:</b> Based on whether the scene is indoor or outdoor, the VLM generates Blender code to construct elements such as walls, terrain, lighting, and sky. An auto-verification loop renders the scene and triggers code refinements to resolve mismatches with the spatial context.
      </li>

      <li>
        <b>Ergonomic Adjustment:</b> To correct inter-object collisions or awkward placements, the VLM jointly optimizes object poses to satisfy soft constraints like contact, alignment, and symmetry, ensuring the final arrangement is both functional and semantically coherent.
      </li>
    </ul>

  </div>
</div>



<div class="row">
  <div class="col-md-8 offset-md-2">
    <h2 id="gallery" tyle="text-align: left">Gallery</h2>
    <p class="text-justify" style="text-align: left; margin-top: 15px;">
      Our approach supports diverse inputs—including text prompts, single images, and unstructured, unposed image collections—and produces coherent, semantically aligned 3D environments across a wide range of styles and settings.
    </p>

    <p class="text-justify" style="text-align: left; margin-top: 0px;">
      <b>Text-conditioned generation. </b> Our method produces scenes 
      that more faithfully preserve semantic alignment, spatial structure, 
      and stylistic intent.
  </p>

    <div class="row justify-content-center align-items-start" style="margin-top: 10px;">
      <!-- Left: Selectable text list -->
      <div class="col-md-3 col-sm-12">
        <div id="videoSelector">
          <p class="video-option" data-src="assets/gallery/1.mp4">
            A Silicon Valley garage-style startup office.
          </p>
          <p class="video-option" data-src="assets/gallery/2.mp4">
            Sherlock Holmes’s 221B Baker Street apartment.
          </p>
          <p class="video-option" data-src="assets/gallery/3.mp4">
            <span style="display: block; font-family: 'KaiTi', '楷体', serif; text-align: center; font-style: italic;">
              竹外桃花三两枝，<br />春江水暖鸭先知。
            </span>
            <span style="font-size: 70%; font-style: italic; text-align: left; display: block;">
              (Beyond the bamboo, peach blossoms bloom,<br />
              The spring river warms — the duck knows soon.)
            </span>
          </p>
          <p class="video-option" data-src="assets/gallery/4.mp4">
            A dystopian set design reminiscent of Blade Runner 2049.
          </p>
        </div>
      </div>
    
      <!-- Right: Single video player -->
      <div class="col-md-9 col-sm-12">
        <video id="mainVideo" src="assets/gallery/1.mp4" controls autoplay loop muted playsinline style="width:100%; object-fit:cover; border-radius:8px;"></video>
      </div>
    </div>

    <p class="text-justify" style="text-align: left; margin-top: 0px;">
      <b>Image-conditioned generation. </b> Our system effectively reconstructs spatial layouts 
      and scene compositions, such as the tilted sofa in a living room, while preserving the stylistic 
      integrity of iconic works like Van Gogh’s Bedroom in Arles.
  </p>

  <div class="row justify-content-center align-items-start" style="margin-top: 10px;">
    <div class="col-md-3 col-sm-12">
      <div id="videoSelector2">
        <p class="video-option2" data-src="assets/gallery/5.mp4">
          <img src="assets/gallery/5.jpg" alt="Video 5" style="width: 100%; border-radius: 8px;">
        </p>
        <p class="video-option2" data-src="assets/gallery/6.mp4">
          <img src="assets/gallery/6.png" alt="Video 6" style="width: 100%; border-radius: 8px;">
        </p>
        <p class="video-option2" data-src="assets/gallery/7.mp4">
          <img src="assets/gallery/7.png" alt="Video 7" style="width: 100%; border-radius: 8px;">
        </p>
      </div>
    </div>

    <div class="col-md-9 col-sm-12">
      <video id="mainVideo2" src="assets/gallery/5.mp4" controls autoplay loop muted playsinline style="width:100%; object-fit:cover; border-radius:8px;"></video>
    </div>
  </div>

  <p class="text-justify" style="text-align: left; margin-top: 0px;">
    <b>Image set as input.</b> Unlike prior methods, which are typically 
    restricted to single-view inputs, our framework naturally accommodates 
    unstructured and unposed image collections and consolidates
    geometric cues from diverse viewpoints into a coherent 3D
    layout. 
</p>

  
  <div class="row justify-content-center align-items-start" style="margin-top: 10px;">
    <div class="col-md-3 col-sm-12 d-flex justify-content-center align-items-center">
      <div class="video-option3">
        <img src="assets/gallery/8.png" alt="Image 8" style="width: 100%; border-radius: 0px;">
      </div>
    </div>
  
    <div class="col-md-9 col-sm-12 d-flex justify-content-center align-items-center">
      <video id="noSelectionVideo" src="assets/gallery/8.mp4" controls autoplay loop muted playsinline style="width:100%; object-fit:cover; border-radius:8px;"></video>
    </div>

  </div>
    
    
    

    
  </div>
</div>








<br/><br/>



       

       
        <div class="col-md-8 offset-md-2 text-start">
          <h3 style="text-align: center">BibTeX</h3>
          <textarea id="bibtex" class="form-control" readonly>
            @article{liu2025agentic,
              title={Agentic 3D Scene Generation with Spatially Contextualized VLMs},
              author={Liu, Xinhang and Tai, Yu-Wing and Tang, Chi-Keung},
              journal={arXiv preprint arXiv:2505.20129},
              year={2025}
            }
          </textarea>
        </div>
        <br/><br/><br/><br/>

      </main>
      <footer>
        <div class="row">
          <div class="col-md-8 offset-md-2 text-start">
            <p class="text-justify" style="text-align: right">
              <i>
                The website template was modified based on
                <a href="https://tesseractworld.github.io/">TesserAct</a>.
              </i>
            </p>
          </div>
        </div>
      </footer>
    </div>
    


   
  </body>

</html>
